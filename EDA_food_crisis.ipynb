{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# helper functions\n",
    "from helper_functions import get_relevant_topics\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Import models\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Helper functions\n",
    "from helper_functions import create_lag_df\n",
    "from helper_functions import plot_ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_southsudan = pd.read_csv(\"data/food_crises_cleaned.csv\", parse_dates=[\"date\"])\n",
    "df_southsudan = pd.read_csv(\"data/cleaned_food_crises.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_southsudan['district'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_southsudan[(df_southsudan[\"date\"] >= \"2008\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['date'] = pd.to_datetime(df_cleaned['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of articles in 2009: 156\n",
      "The number of articles in 2010: 312\n",
      "The number of articles in 2011: 312\n",
      "The number of articles in 2012: 312\n",
      "The number of articles in 2013: 312\n",
      "The number of articles in 2014: 312\n",
      "The number of articles in 2015: 312\n",
      "The number of articles in 2016: 234\n",
      "The number of articles in 2017: 234\n",
      "The number of articles in 2018: 234\n",
      "The number of articles in 2019: 234\n",
      "The number of articles in 2020: 78\n"
     ]
    }
   ],
   "source": [
    "for i in range(2009, 2020 + 1):\n",
    "    num_of_articles = len(df_cleaned[(df_cleaned['ipc'].notnull()) & (df_cleaned['date'] >= f\"{i}-01-01\") & (df_cleaned['date']< f\"{i+1}-01-01\")])\n",
    "    print(f\"The number of articles in {i}: {num_of_articles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleaned.to_csv(\"data/cleaned_food_crises.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection = [\"ipc\", \"ha\", \"ndvi_mean\", \"ndvi_anom\", \"rain_mean\", \"rain_anom\", \"et_mean\", \"et_anom\",\n",
    "#              \"count_violence\", \"sum_fatalities\", \"food_price_idx\", \"area\", \"cropland_pct\", \"pop\",\n",
    "#              \"ruggedness_mean\", \"pasture_pct\"]\n",
    "# sns.pairplot(df_cleaned[selection], hue='ipc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/egor/Desktop/Study Materials/DC3-Group-13/EDA_food_crisis.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/egor/Desktop/Study%20Materials/DC3-Group-13/EDA_food_crisis.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_cleaned\u001b[39m.\u001b[39minfo()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/egor/Desktop/Study Materials/DC3-Group-13/EDA_food_crisis.ipynb Cell 10\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/egor/Desktop/Study%20Materials/DC3-Group-13/EDA_food_crisis.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/egor/Desktop/Study%20Materials/DC3-Group-13/EDA_food_crisis.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Assuming you have a DataFrame named df with a 'date' column\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/egor/Desktop/Study%20Materials/DC3-Group-13/EDA_food_crisis.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# and other columns with missing data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/egor/Desktop/Study%20Materials/DC3-Group-13/EDA_food_crisis.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/egor/Desktop/Study%20Materials/DC3-Group-13/EDA_food_crisis.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Extract the year from the 'date' column and create a new 'year' column\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/egor/Desktop/Study%20Materials/DC3-Group-13/EDA_food_crisis.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m df_cleaned[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_cleaned[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39myear\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/egor/Desktop/Study%20Materials/DC3-Group-13/EDA_food_crisis.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Calculate the count of missing values per year\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/egor/Desktop/Study%20Materials/DC3-Group-13/EDA_food_crisis.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m missing_data_per_year \u001b[39m=\u001b[39m df_cleaned\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum())\u001b[39m.\u001b[39mreset_index()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_cleaned' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = df_cleaned.copy()\n",
    "df_prediction.set_index([\"date\", \"district\"], inplace=True) # Set index\n",
    "df_prediction = create_lag_df(df_prediction, ['count_violence', 'ndvi_anom'], 3, rolling=6) # 3-month-lagged rolling mean window of size 6\n",
    "df_prediction = create_lag_df(df_prediction, ['food_price_idx'], 3, difference=True, rolling=6) # difference of the 3-month-lagged rolling mean window of size 6\n",
    "# df_prediction = create_lag_df(df_prediction, ['ipc'], 1, dropna=True) # 1-month-lag\n",
    "# df_prediction = create_lag_df(df_prediction, ['ipc'], 2, dropna=True) # 2-month-lag\n",
    "df_prediction = create_lag_df(df_prediction, ['ipc'], 3, dropna=True) # 3-month-lag\n",
    "df_prediction = create_lag_df(df_prediction, ['ipc'], 6, dropna=True) # 6-month-lag\n",
    "df_prediction = create_lag_df(df_prediction, ['ipc'], 12, dropna=True) # 12-month-lag\n",
    "df_prediction = df_prediction.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2106"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = [\"centx\", \"centy\", \"ipc\", \"Unnamed: 0\"]\n",
    "X_all_available = df_prediction.copy().drop(columns=drop)\n",
    "Y = df_prediction['ipc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 2106 entries, (Timestamp('2012-07-01 00:00:00'), 'Bor') to (Timestamp('2020-02-01 00:00:00'), 'Malakal')\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   ha                    2106 non-null   float64\n",
      " 1   ndvi_mean             2106 non-null   float64\n",
      " 2   ndvi_anom             2106 non-null   float64\n",
      " 3   rain_mean             2106 non-null   float64\n",
      " 4   rain_anom             2106 non-null   float64\n",
      " 5   et_mean               2106 non-null   float64\n",
      " 6   et_anom               2106 non-null   float64\n",
      " 7   count_violence        2106 non-null   int64  \n",
      " 8   sum_fatalities        2106 non-null   int64  \n",
      " 9   food_price_idx        2106 non-null   float64\n",
      " 10  area                  2106 non-null   float64\n",
      " 11  cropland_pct          2106 non-null   float64\n",
      " 12  pop                   2106 non-null   float64\n",
      " 13  ruggedness_mean       2106 non-null   float64\n",
      " 14  pasture_pct           2106 non-null   float64\n",
      " 15  count_violence_lag_3  2106 non-null   float64\n",
      " 16  ndvi_anom_lag_3       2106 non-null   float64\n",
      " 17  food_price_idx_lag_3  2106 non-null   float64\n",
      " 18  ipc_lag_3             2106 non-null   float64\n",
      " 19  ipc_lag_6             2106 non-null   float64\n",
      " 20  ipc_lag_12            2106 non-null   float64\n",
      "dtypes: float64(19), int64(2)\n",
      "memory usage: 359.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X_all_available.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 2106 entries, (Timestamp('2012-07-01 00:00:00'), 'Bor') to (Timestamp('2020-02-01 00:00:00'), 'Malakal')\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   count_violence_lag_3  2106 non-null   float64\n",
      " 1   ndvi_anom_lag_3       2106 non-null   float64\n",
      " 2   food_price_idx_lag_3  2106 non-null   float64\n",
      " 3   ipc_lag_3             2106 non-null   float64\n",
      " 4   ipc_lag_6             2106 non-null   float64\n",
      " 5   ipc_lag_12            2106 non-null   float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 112.9+ KB\n"
     ]
    }
   ],
   "source": [
    "X = X_all_available.copy().iloc[:, 15:]\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.610 total time=   0.3s\n",
      "[CV 3/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.583 total time=   0.4s\n",
      "[CV 4/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.644 total time=   0.4s\n",
      "[CV 1/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.580 total time=   0.3s\n",
      "[CV 2/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.610 total time=   0.3s\n",
      "[CV 3/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.583 total time=   0.4s\n",
      "[CV 5/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.612 total time=   0.4s\n",
      "[CV 5/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.612 total time=   0.4s\n",
      "[CV 4/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.644 total time=   0.4s\n",
      "[CV 1/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.580 total time=   0.4s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.634 total time=   1.0s\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.586 total time=   1.0s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.651 total time=   0.9s\n",
      "[CV 1/5] END ....C=1, gamma=auto, kernel=linear;, score=0.586 total time=   1.0s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.597 total time=   1.1s\n",
      "[CV 2/5] END ....C=1, gamma=auto, kernel=linear;, score=0.634 total time=   1.0s\n",
      "[CV 4/5] END ....C=1, gamma=auto, kernel=linear;, score=0.651 total time=   0.9s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.619 total time=   1.2s\n",
      "[CV 3/5] END ....C=1, gamma=auto, kernel=linear;, score=0.597 total time=   1.1s\n",
      "[CV 5/5] END ....C=1, gamma=auto, kernel=linear;, score=0.619 total time=   1.1s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.641 total time=   2.0s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.590 total time=   2.1s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.654 total time=   2.0s\n",
      "[CV 2/5] END ...C=10, gamma=auto, kernel=linear;, score=0.641 total time=   2.0s\n",
      "[CV 4/5] END ...C=10, gamma=auto, kernel=linear;, score=0.654 total time=   1.9s\n",
      "[CV 1/5] END ...C=10, gamma=auto, kernel=linear;, score=0.590 total time=   2.1s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.603 total time=   2.3s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.619 total time=   2.3s\n",
      "[CV 3/5] END ...C=10, gamma=auto, kernel=linear;, score=0.603 total time=   2.4s\n",
      "[CV 5/5] END ...C=10, gamma=auto, kernel=linear;, score=0.619 total time=   2.3s\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.600 total time=   5.3s\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.620 total time=   4.4s\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.664 total time=   5.6s\n",
      "[CV 1/5] END ..C=100, gamma=auto, kernel=linear;, score=0.600 total time=   4.0s\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.658 total time=   4.8s\n",
      "[CV 3/5] END ..C=100, gamma=auto, kernel=linear;, score=0.620 total time=   4.4s\n",
      "[CV 4/5] END ..C=100, gamma=auto, kernel=linear;, score=0.658 total time=   4.5s\n",
      "[CV 2/5] END ..C=100, gamma=auto, kernel=linear;, score=0.664 total time=   5.2s\n",
      "[CV 5/5] END ..C=100, gamma=auto, kernel=linear;, score=0.633 total time=   5.1s\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.633 total time=   6.1s\n",
      "{'C': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.72      0.73      0.72       125\n",
      "         2.0       0.61      0.63      0.62       218\n",
      "         3.0       0.64      0.74      0.68       235\n",
      "         4.0       0.00      0.00      0.00        54\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.64       632\n",
      "   macro avg       0.39      0.42      0.41       632\n",
      "weighted avg       0.59      0.64      0.61       632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "                        X,Y,test_size = 0.30, random_state = 101) \n",
    "\n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'gamma':['scale', 'auto'],\n",
    "              'kernel': ['linear']}  \n",
    "   \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3,n_jobs=-1) \n",
    "   \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n",
    " \n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "grid_predictions = grid.predict(X_test) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.75      0.66      0.71       125\n",
      "         2.0       0.64      0.75      0.69       218\n",
      "         3.0       0.70      0.76      0.73       235\n",
      "         4.0       0.45      0.09      0.15        54\n",
      "\n",
      "    accuracy                           0.68       632\n",
      "   macro avg       0.64      0.57      0.57       632\n",
      "weighted avg       0.67      0.68      0.66       632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "\n",
    "print(CV_rfc.best_params_) \n",
    "rfc_grid_predictions = CV_rfc.predict(X_test) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, rfc_grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
